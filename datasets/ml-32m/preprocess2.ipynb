{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df_origin = pd.read_pickle('./small_Books.pkl')\n",
    "meta_df_origin = pd.read_pickle('./small_meta_Books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df = book_df_origin.copy()\n",
    "meta_df = meta_df_origin.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'parent_asin', 'genres', 'imdbId', 'tmdbId', 'startYear',\n",
      "       'titleType', 'runtimeMinutes', 'endYear', 'publish_time'],\n",
      "      dtype='object')\n",
      "Index(['user_id', 'parent_asin', 'rating', 'timestamp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(meta_df.columns)\n",
    "print(book_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. seperate cold-start and warm-start items according to item publish time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_title2id_dict = {}\n",
    "id_num = 0 \n",
    "unique_titles = meta_df['title'].unique().tolist()\n",
    "for title in unique_titles:\n",
    "    original_title2id_dict[title] = id_num\n",
    "    id_num+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['title_idx'] = meta_df['title'].apply(lambda x:original_title2id_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'parent_asin', 'rating', 'timestamp'], dtype='object') Index(['title', 'parent_asin', 'genres', 'imdbId', 'tmdbId', 'startYear',\n",
      "       'titleType', 'runtimeMinutes', 'endYear', 'publish_time', 'title_idx'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(book_df.columns, meta_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_df['timestamp'] = pd.to_datetime(book_df['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_meta_df = meta_df.copy()[['title','parent_asin','title_idx','publish_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_book_df = pd.merge(left = book_df, right=partial_meta_df,how = 'left',on='parent_asin', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'parent_asin', 'rating', 'timestamp', 'title', 'title_idx',\n",
      "       'publish_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_book_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_book_df['publish_time'].replace('\\\\N', np.nan, inplace=True)\n",
    "merged_book_df.dropna(inplace=True)\n",
    "merged_book_df['publish_time'] = merged_book_df['publish_time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_book_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['uid',  'iid','rating', 'timestamp', 'title', 'title_idx','publish_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_publist_earliest_time = data.groupby('title_idx').agg({'publish_time':'min'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           publish_time\n",
      "title_idx              \n",
      "0                  1995\n",
      "1                  1995\n",
      "2                  1995\n",
      "3                  1995\n",
      "4                  1995\n",
      "...                 ...\n",
      "87377              2022\n",
      "87378              2023\n",
      "87379              2021\n",
      "87380              1968\n",
      "87381              2023\n",
      "\n",
      "[84055 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(item_publist_earliest_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_publish_data = item_publist_earliest_time[item_publist_earliest_time['publish_time'] >= 2023]\n",
    "cold_publish_items = cold_publish_data.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 22:09:08\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "cold_data = data[data['title_idx'].isin(cold_publish_items)]\n",
    "print(cold_data['timestamp'].min())\n",
    "print(cold_data['publish_time'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_review_earliest_time = data.groupby('title_idx').agg({'timestamp':'min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_review_data = item_review_earliest_time[item_review_earliest_time['timestamp'] >= pd.to_datetime('2023-01-01')]\n",
    "cold_review_items = cold_review_data.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835\n",
      "4710\n"
     ]
    }
   ],
   "source": [
    "print(len(cold_publish_items))\n",
    "print(len(cold_review_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_items = set(cold_review_items).intersection(set(cold_publish_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827\n"
     ]
    }
   ],
   "source": [
    "print(len(cold_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.get warm_train, warm_test, cold_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_start_time = '2020-01-01'\n",
    "cold_start_time = '2023-06-01'\n",
    "cold_end_time = '2023-07-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_book_df.copy()\n",
    "data.columns = ['uid',  'iid','rating', 'timestamp', 'title', 'title_idx','publish_time']\n",
    "cold_data = data[data['title_idx'].isin(cold_items)]\n",
    "uncold_data = data[~data['title_idx'].isin(cold_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete cold data' interactions\n",
    "cold_data_test = cold_data[(cold_data['timestamp'] >= pd.to_datetime(cold_start_time)) & (cold_data['timestamp'] <= pd.to_datetime(cold_end_time))]\n",
    "cold_items_test = cold_data_test['title_idx'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_items = uncold_data['iid'].unique().tolist()\n",
    "preserve_warm_items = list((set(old_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "preserve_warm_data = uncold_data[uncold_data['iid'].isin(preserve_warm_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4245008\n",
      "146745\n"
     ]
    }
   ],
   "source": [
    "# process only warm_data\n",
    "preserve_warm_data_test_index = (preserve_warm_data['timestamp'] >= pd.to_datetime(cold_start_time)) & (preserve_warm_data['timestamp'] <= pd.to_datetime(cold_end_time))\n",
    "preserve_warm_data_train_index= (preserve_warm_data['timestamp'] >= pd.to_datetime(warm_start_time)) & (preserve_warm_data['timestamp'] < pd.to_datetime(cold_start_time))\n",
    "preserve_warm_data_test = preserve_warm_data[preserve_warm_data_test_index]\n",
    "preserve_warm_data_train = preserve_warm_data[preserve_warm_data_train_index]\n",
    "print(preserve_warm_data_train.shape[0])\n",
    "print(preserve_warm_data_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2422927/1316126967.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  preserve_warm_data_train['env'] = 0 # warm train\n",
      "/tmp/ipykernel_2422927/1316126967.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  preserve_warm_data_test['env'] = 1 # warm test\n",
      "/tmp/ipykernel_2422927/1316126967.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cold_data_test['env'] = 3 # cold\n"
     ]
    }
   ],
   "source": [
    "preserve_warm_data_train['env'] = 0 # warm train\n",
    "preserve_warm_data_test['env'] = 1 # warm test\n",
    "cold_data_test['env'] = 3 # cold\n",
    "all_data = pd.concat([preserve_warm_data_train,preserve_warm_data_test,cold_data_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_users(all_data):\n",
    "    user_cnt = all_data['uid'].value_counts()\n",
    "    warm_users = user_cnt[user_cnt >= 10].index.tolist()\n",
    "    all_data = all_data[all_data['uid'].isin(warm_users)]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filer_items(all_data):\n",
    "    item_cnt = all_data['iid'].value_counts()\n",
    "    filer_items = item_cnt[item_cnt >=10].index.tolist()\n",
    "    all_data = all_data[all_data['iid'].isin(filer_items)]\n",
    "\n",
    "    # filter items again, to make sure the warm items in the test set are warm---delete items with less than 10 inters in the training set\n",
    "    train_warm_cnt = all_data[all_data['env'] == 0]['iid'].value_counts()\n",
    "    delete_items = train_warm_cnt[train_warm_cnt < 10].index.unique().tolist()\n",
    "    all_data = all_data[~all_data['iid'].isin(delete_items)]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = filer_items(all_data)\n",
    "all_data = filter_users(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4252144\n",
      "warm train inter num 4106115\n",
      "warm evaluate inter num 141439\n",
      "cold evaluate inter num 4590\n"
     ]
    }
   ],
   "source": [
    "print(all_data.shape[0])\n",
    "print('warm train inter num',all_data[all_data['env'] == 0].shape[0]) # warm_train\n",
    "print('warm evaluate inter num',all_data[all_data['env'] == 1].shape[0]) # warm_test\n",
    "print('cold evaluate inter num',all_data[all_data['env'] == 3].shape[0]) # cold (cold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_data = all_data[all_data['env'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = cold_data['iid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.save data for TALLRec and CF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_asin to iid\n",
    "parent_asin2iid_dict = {}\n",
    "num = 0\n",
    "for parent_asin in all_data['iid'].unique().tolist():\n",
    "    parent_asin2iid_dict[parent_asin] = num\n",
    "    num += 1\n",
    "all_data['iid'] = all_data['iid'].apply(lambda x: parent_asin2iid_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17402\n"
     ]
    }
   ],
   "source": [
    "print(len(parent_asin2iid_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_asin to iid\n",
    "user_id2uid_dict = {}\n",
    "num = 0\n",
    "for user_id in all_data['uid'].unique().tolist():\n",
    "    user_id2uid_dict[user_id] = num\n",
    "    num += 1\n",
    "all_data['uid'] = all_data['uid'].apply(lambda x: user_id2uid_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26533\n"
     ]
    }
   ],
   "source": [
    "print(len(user_id2uid_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uid', 'iid', 'rating', 'timestamp', 'title', 'title_idx',\n",
      "       'publish_time', 'env'],\n",
      "      dtype='object')\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(all_data.columns)\n",
    "print(all_data['publish_time'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.sort_values(by = 'timestamp', inplace=True, ascending=True)\n",
    "all_data['label'] = all_data['rating'].apply(lambda x: 1 if x>=4 else 0)\n",
    "all_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   iid  \\\n",
      "uid                                                      \n",
      "0    [24, 16, 36, 39, 9, 47, 44, 8, 7, 12, 28, 13, ...   \n",
      "\n",
      "                                                 label  \\\n",
      "uid                                                      \n",
      "0    [1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, ...   \n",
      "\n",
      "                                                 title  \\\n",
      "uid                                                      \n",
      "0    [Shaun of the Dead (2004), Amelie (Fabuleux de...   \n",
      "\n",
      "                                             timestamp  \\\n",
      "uid                                                      \n",
      "0    [2020-01-19 17:08:33, 2020-01-19 17:10:50, 202...   \n",
      "\n",
      "                                                   env  \n",
      "uid                                                     \n",
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "u_inter_all = all_data.groupby('uid').agg({'iid':list, 'label':list, 'title':list, 'timestamp':list, 'env':list})\n",
    "print(u_inter_all.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def deal_with_each_u(x,u):\n",
    "    items = np.array(x.iid)\n",
    "    labels = np.array(x.label)\n",
    "    titles = np.array(x.title)\n",
    "    timestamp = np.array(x.timestamp)\n",
    "    env = np.array(x.env)\n",
    "    his = [0] # adding a '0' by default\n",
    "    his_title = ['']\n",
    "    results = []\n",
    "    for i in range(items.shape[0]):\n",
    "        results.append((u, items[i], timestamp[i], np.array(his), copy.copy(his_title),titles[i], labels[i],env[i]))\n",
    "        # training data\n",
    "        if labels[i] > 0: # positive \n",
    "            his.append(items[i])\n",
    "            his_title.append(titles[i])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for u in u_inter_all.index:\n",
    "    results.extend(deal_with_each_u(u_inter_all.loc[u],u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_, i_, time_, label_, his_, his_title, title_,env_ = [],[],[],[],[],[],[],[]\n",
    "for re_ in results:\n",
    "        u_.append(re_[0])\n",
    "        i_.append(re_[1])\n",
    "        time_.append(re_[2])\n",
    "        his_.append(re_[3][-15:])\n",
    "        his_title.append(re_[4][-15:])\n",
    "        title_.append(re_[5])\n",
    "        label_.append(re_[6])\n",
    "        env_.append(re_[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame({\"uid\":u_,'iid':i_,'label':label_, 'timestamp': time_ , 'his':his_,'his_title':his_title,'title':title_,'env':env_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4252144, 8)\n"
     ]
    }
   ],
   "source": [
    "print(all_data.shape)\n",
    "all_data.sort_values(by = 'timestamp', ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def under_sample(df, p):\n",
    "    items = df['iid'].unique().tolist()\n",
    "    random.seed(2024)\n",
    "    random.shuffle(items)\n",
    "    preserve_items = items[ : int(len(items) * p)]\n",
    "    new_df = df[df['iid'].isin(preserve_items)]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm train inter num 4106115\n",
      "warm evaluate inter num 14359\n",
      "cold evaluate inter num 4590\n"
     ]
    }
   ],
   "source": [
    "train_data = all_data[all_data['env'] == 0]\n",
    "warm_test = all_data[all_data['env'] == 1]\n",
    "cold_test = all_data[all_data['env'] == 3]\n",
    "#  Under-sample evaluation data for warm items to make their quantity close to that of cold items,\n",
    "#  as we use the metrics from the mixed validation set to early stop, following previous work.\n",
    "warm_test = under_sample(warm_test, p = 0.1)\n",
    "print('warm train inter num', train_data.shape[0]) # warm_train\n",
    "print('warm evaluate inter num', warm_test.shape[0]) # warm_test\n",
    "print('cold evaluate inter num', cold_test.shape[0]) # cold (cold_test)\n",
    "mix_test = pd.concat((warm_test, cold_test))\n",
    "unique_iids = mix_test['iid'].unique().tolist()\n",
    "valid_data = []\n",
    "test_data = []\n",
    "for iid in unique_iids:\n",
    "    iid_data = mix_test.loc[mix_test['iid'] == iid]\n",
    "    split_index = len(iid_data) // 2  \n",
    "    valid_data.append(iid_data.iloc[:split_index])\n",
    "    test_data.append(iid_data.iloc[split_index:])\n",
    "valid_all = pd.concat(valid_data)\n",
    "test_all = pd.concat(test_data)\n",
    "warm_valid = valid_all[valid_all['env'] == 1]\n",
    "cold_valid = valid_all[valid_all['env'] == 3]\n",
    "warm_test = test_all[test_all['env'] == 1]\n",
    "cold_test = test_all[test_all['env'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle('./train_1.pkl')  # train_warm\n",
    "valid_all.to_pickle('./valid_0.pkl') # valid_mix\n",
    "test_all.to_pickle('./test_0.pkl') # valid_mix\n",
    "warm_valid.to_pickle('./valid_1.pkl') # valid_warm\n",
    "cold_valid.to_pickle('./valid_2.pkl') # valid_cold\n",
    "warm_test.to_pickle('./test_1.pkl') # test_warm\n",
    "cold_test.to_pickle('./test_2.pkl')  # test_cold\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
